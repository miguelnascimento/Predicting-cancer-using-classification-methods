
Run this first! Necessary packages and code to run previously:
```{r}
library(kknn)
library(caret)
library(corrplot)
library(reshape2)
library(ggplot2)
library(factoextra)
library(readr)
library(rattle)
library(rpart.plot)

train.control <- trainControl(method = "cv",number = 5)

metricas <- function(x){
acc  <- round(sum(diag(x))/sum(x) ,3)
tpr  <- round(x[4]/(x[3]+x[4]) ,3)
fpr  <- round(x[2]/(x[2]+x[1]) ,3)
prec <- round(x[4]/(x[4]+x[2]) ,3)
print(paste0("Accuracy: ", acc  ))
print(paste0("TPR: ", tpr          ))
print(paste0("FPR: ", fpr         ))
print(paste0("Precision: ", prec    ))
print(paste0("F1 Score: ", (2*tpr*prec)/(tpr+prec) ))

}
```



Import the datasets in this chunk. After importing each dataset, the column "labels" needs to be encoded as factor, and the column "X1" needs to be deleted (turned into NULL). The code for this is included in the chunk, after the lines of code that import each dataset.
```{r}
arcene <- read_csv("Datasets/arcene.csv")
arcene_treino <- read_csv("Datasets/arcene_treino.csv")
arcene_teste <- read_csv("Datasets/arcene_teste.csv")
arcene$labels <- as.factor(arcene$labels)
arcene_treino$labels <- as.factor(arcene_treino$labels)
arcene_teste$labels <- as.factor(arcene_teste$labels)


arcene_unlabeled <- read_csv("Datasets/arcene_unlabeled.csv")
arcene_unlabeled_treino <- read_csv("Datasets/arcene_unlabeled_treino.csv")
arcene_unlabeled_teste <- read_csv("Datasets/arcene_unlabeled_teste.csv")

#The datasets that we will be using in our methods:
arcene_corr_75 <- read_csv("Datasets/arcene_corr_75.csv")
arcene_corr_75_treino <- read_csv("Datasets/arcene_corr_75_treino.csv")
arcene_corr_75_teste <- read_csv("Datasets/arcene_corr_75_teste.csv")
arcene_corr_75$labels <- as.factor(arcene_corr_75$labels)
arcene_corr_75_treino$labels <- as.factor(arcene_corr_75_treino$labels)
arcene_corr_75_teste$labels <- as.factor(arcene_corr_75_teste$labels)
arcene_corr_75$X1<-NULL
arcene_corr_75_treino$X1 <- NULL
arcene_corr_75_teste$X1 <- NULL


arcene_corr_85 <- read_csv("Datasets/arcene_corr_85.csv")
arcene_corr_85_treino <- read_csv("Datasets/arcene_corr_85_treino.csv")
arcene_corr_85_teste <- read_csv("Datasets/arcene_corr_85_teste.csv")
arcene_corr_85$labels <- as.factor(arcene_corr_85$labels)
arcene_corr_85_treino$labels <- as.factor(arcene_corr_85_treino$labels)
arcene_corr_85_teste$labels <- as.factor(arcene_corr_85_teste$labels)
arcene_corr_85$X1<-NULL
arcene_corr_85_treino$X1 <- NULL
arcene_corr_85_teste$X1 <- NULL


arcene_corr_95 <- read_csv("Datasets/arcene_corr_95.csv")
arcene_corr_95_treino <- read_csv("Datasets/arcene_corr_95_treino.csv")
arcene_corr_95_teste <- read_csv("Datasets/arcene_corr_95_teste.csv")
arcene_corr_95$labels <- as.factor(arcene_corr_95$labels)
arcene_corr_95_treino$labels <- as.factor(arcene_corr_95_treino$labels)
arcene_corr_95_teste$labels <- as.factor(arcene_corr_95_teste$labels)
arcene_corr_95$X1<-NULL
arcene_corr_95_treino$X1 <- NULL
arcene_corr_95_teste$X1 <- NULL


arcene_corr_99 <- read_csv("Datasets/arcene_corr_99.csv")
arcene_corr_99_treino <- read_csv("Datasets/arcene_corr_99_treino.csv")
arcene_corr_99_teste <- read_csv("Datasets/arcene_corr_99_teste.csv")
arcene_corr_99$labels <- as.factor(arcene_corr_99$labels)
arcene_corr_99_treino$labels <- as.factor(arcene_corr_99_treino$labels)
arcene_corr_99_teste$labels <- as.factor(arcene_corr_99_teste$labels)
arcene_corr_99$X1<-NULL
arcene_corr_99_treino$X1 <- NULL
arcene_corr_99_teste$X1 <- NULL


arcene_pca_75 <- read_csv("Datasets/arcene_pca_75.csv")
arcene_pca_75_treino <- read_csv("Datasets/arcene_pca_75_treino.csv")
arcene_pca_75_teste <- read_csv("Datasets/arcene_pca_75_teste.csv")
arcene_pca_75$labels <- as.factor(arcene_pca_75$labels)
arcene_pca_75_treino$labels <- as.factor(arcene_pca_75_treino$labels)
arcene_pca_75_teste$labels <- as.factor(arcene_pca_75_teste$labels)
arcene_pca_75$X1<-NULL
arcene_pca_75_treino$X1 <- NULL
arcene_pca_75_teste$X1 <- NULL


arcene_pca_85 <- read_csv("Datasets/arcene_pca_85.csv")
arcene_pca_85_treino <- read_csv("Datasets/arcene_pca_85_treino.csv")
arcene_pca_85_teste <- read_csv("Datasets/arcene_pca_85_teste.csv")
arcene_pca_85$labels <- as.factor(arcene_pca_85$labels)
arcene_pca_85_treino$labels <- as.factor(arcene_pca_85_treino$labels)
arcene_pca_85_teste$labels <- as.factor(arcene_pca_85_teste$labels)
arcene_pca_85$X1<-NULL
arcene_pca_85_treino$X1 <- NULL
arcene_pca_85_teste$X1 <- NULL


arcene_pca_95 <- read_csv("Datasets/arcene_pca_95.csv")
arcene_pca_95_treino <- read_csv("Datasets/arcene_pca_95_treino.csv")
arcene_pca_95_teste <- read_csv("Datasets/arcene_pca_95_teste.csv")
arcene_pca_95$labels <- as.factor(arcene_pca_95$labels)
arcene_pca_95_treino$labels <- as.factor(arcene_pca_95_treino$labels)
arcene_pca_95_teste$labels <- as.factor(arcene_pca_95_teste$labels)
arcene_pca_95$X1<-NULL
arcene_pca_95_treino$X1 <- NULL
arcene_pca_95_teste$X1 <- NULL
```



K-Nearest Neighbours method:
```{r}
n_vizinhos = c(1,3,5,7,9,11,13,15,17)

####################### Correlation 99% ####
set.seed(2020)
pred_knn_corr_99 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_corr_99_treino
                        )


fit_knn_corr_99 <- predict(pred_knn_corr_99, arcene_corr_99_teste)
cnf_mtx_knn_corr_99 <- confusionMatrix(arcene_corr_99_teste$labels, fit_knn_corr_99)
knn_corr_99_accuracy_list <- pred_knn_corr_99$results$Accuracy

metricas(cnf_mtx_knn_corr_99$table)

####################### Correlation 95% ####
set.seed(2020)
pred_knn_corr_95 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_corr_95_treino
                        )

fit_knn_corr_95 <- predict(pred_knn_corr_95, arcene_corr_95_teste)
cnf_mtx_knn_corr_95 <- confusionMatrix(arcene_corr_95_teste$labels, fit_knn_corr_95)
knn_corr_95_accuracy_list <- pred_knn_corr_95$results$Accuracy

metricas(cnf_mtx_knn_corr_95$table)

####################### Correlation 85% ####
set.seed(2020)
pred_knn_corr_85 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_corr_85_treino
                        )
#  

fit_knn_corr_85 <- predict(pred_knn_corr_85, arcene_corr_85_teste)
cnf_mtx_knn_corr_85 <- confusionMatrix(arcene_corr_85_teste$labels, fit_knn_corr_85)
knn_corr_85_accuracy_list <- pred_knn_corr_85$results$Accuracy

metricas(cnf_mtx_knn_corr_85$table)

####################### Correlation 75% ####
set.seed(2020)
pred_knn_corr_75 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_corr_75_treino
                        )
#  

fit_knn_corr_75 <- predict(pred_knn_corr_75, arcene_corr_75_teste)
cnf_mtx_knn_corr_75 <- confusionMatrix(arcene_corr_75_teste$labels, fit_knn_corr_75)
knn_corr_75_accuracy_list <- pred_knn_corr_75$results$Accuracy

metricas(cnf_mtx_knn_corr_75$table)

####################### PCA 95% ####
set.seed(2020)
pred_knn_pca_95 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_95_treino
                        )
#  

fit_knn_pca_95 <- predict(pred_knn_pca_95, arcene_pca_95_teste)
cnf_mtx_knn_pca_95 <- confusionMatrix(arcene_pca_95_teste$labels, fit_knn_pca_95)
knn_pca_95_accuracy_list <- pred_knn_pca_95$results$Accuracy

metricas(cnf_mtx_knn_pca_95$table)

####################### PCA 85% ####
set.seed(2020)
pred_knn_pca_85 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_85_treino
                        )
#  

fit_knn_pca_85 <- predict(pred_knn_pca_85, arcene_pca_85_teste)
cnf_mtx_knn_pca_85 <- confusionMatrix(arcene_pca_85_teste$labels, fit_knn_pca_85)
knn_pca_85_accuracy_list <- pred_knn_pca_85$results$Accuracy

metricas(cnf_mtx_knn_pca_85$table)

####################### PCA 75% ####
set.seed(2020)
pred_knn_pca_75 <- train(labels~.,
                     method     = "knn",
                     tuneGrid   = expand.grid(k = n_vizinhos),
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_75_treino
                        )
#  

fit_knn_pca_75 <- predict(pred_knn_pca_75, arcene_pca_75_teste)
cnf_mtx_knn_pca_75 <- confusionMatrix(arcene_pca_75_teste$labels, fit_knn_pca_75)
knn_pca_75_accuracy_list <- pred_knn_pca_75$results$Accuracy

metricas(cnf_mtx_knn_pca_75$table)


#Plots and charts:
results=melt(data.frame(Full_Dataset=c(0.84,0.789,0.129,0.789,0.789),
                    Corr_95=c(0.8,0.714,0.138,0.789,0.750),
                    Corr_85=c(0.66,0.538,0.208,0.737,0.622),
                    Corr_75=c(0.56,0.452,0.263,0.737,0.560),
                    Pca_75 = c(0.82,0.778,0.156,0.737,0.757),
                    Pca_85 = c(0.84,0.762,0.103,0.842,0.8),
                    Pca_95 = c(0.82,0.727,0.107,0.842,0.78),
                    scores=c("Acc","TPR","FPR","Precision","F1_Score")))
colnames(results)[2]<-"Process"
png(filename="knn_resultados.png",width=1000,height=800,units="px")
ggplot(results,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")
dev.off()


colours_knn = c("black", "midnightblue","violetred","orchid2","springgreen4", "red3", "tomato")
legendas_knn = c("Full","Corr_95","Corr_85","Corr_75","Pca_95","Pca_85","Pca_75")
png(filename="knn_roc.png",width=450,height=300,units="px")
plot(0:1, 0:1, type="n",main="ROC chart for KNN",xlab="FPR",ylab="TPR")
points(0.129,0.789, col = colours_knn[1], pch=4)
points(0.138,0.714, col = colours_knn[2], pch=15)
points(0.208,0.538, col = colours_knn[3], pch=15)
points(0.263,0.452, col = colours_knn[4], pch=15)
points(0.107,0.727, col = colours_knn[5], pch=19)
points(0.103,0.762, col = colours_knn[6], pch=19)
points(0.156,0.778, col = colours_knn[7], pch=19)
points(1,1, col = colours_knn[1], pch=20)
points(0,0, col = colours_knn[1], pch=20)
points(0,1, col = colours_knn[1], pch=20)
legend(0.75, 0.9, legend=legendas_knn, col=colours_knn, pch=c(4,15,15,15,19,19,19))


x<-c(1,3,5,7,9,11,13,15,17)
#plot(0:1,0:17, type="l")
png(filename="knn_acc.png",width=540,height=360,units="px")
plot(x, c(1,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5),col="white", pch=4 , type="b", xlab="Number of Neighbours", ylab="Accuracy")
lines(x, knn_corr_99_accuracy_list, pch=4, col=colours_knn[1], type="b")
lines(x, knn_corr_95_accuracy_list, pch=15, col=colours_knn[2], type="b")
lines(x, knn_corr_85_accuracy_list, pch=15, col=colours_knn[3], type="b")
lines(x, knn_corr_75_accuracy_list, pch=15, col=colours_knn[4], type="b")
lines(x, knn_pca_95_accuracy_list, pch=19, col=colours_knn[5], type="b")
lines(x, knn_pca_85_accuracy_list, pch=19, col=colours_knn[6], type="b")
lines(x, knn_pca_75_accuracy_list, pch=19, col=colours_knn[7], type="b")
legend(13, 0.99, legend=legendas_knn[1:4], col=colours_knn[1:4], pch=c(4,15,15,15))
legend(9, 0.99, legend=legendas_knn[5:7], col=colours_knn[5:7], pch=c(19,19,19))

```



Decision Trees and Random Forests methods:
```{r}
set.seed(2020)

####################### PCA 75% ####

# Decision tree (Complexity Parameter)
# Train the model
pred.pca.75.cp <- train(labels~.,
                        method     = "rpart",
                        trControl  = train.control,
                        metric     = "Accuracy",
                        data       = arcene_pca_75_treino)
# Summarize the results
print(pred.pca.75.cp)

# Plot Accuracy&Kappa
plot(pred.pca.75.cp$results$cp, pred.pca.75.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.7))
lines(pred.pca.75.cp$results$cp, pred.pca.75.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.75.cp <- predict(pred.pca.75.cp,newdata = arcene_pca_75_teste)
cm.pca.75.cp <- confusionMatrix(arcene_pca_75_teste$labels,fit.pca.75.cp)

# Decision tree (Max Depth)
# Train the model
pred.pca.75.depth <- train(labels~.,
                           method     = "rpart2",
                           trControl  = train.control,
                           metric     = "Accuracy",
                           data       = arcene_pca_75_treino)
# Summarize the results
print(pred.pca.75.depth)

# Plot Accuracy&Kappa
plot(pred.pca.75.depth$results$maxdepth, pred.pca.75.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0.2,0.8))
lines(pred.pca.75.depth$results$maxdepth, pred.pca.75.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.75.depth <- predict(pred.pca.75.depth,newdata = arcene_pca_75_teste)
cm.pca.75.depth <- confusionMatrix(arcene_pca_75_teste$labels,fit.pca.75.depth)

# Random Forests
# Train the model
pred.pca.75.rf <- train(labels~.,
                        method     = "rf",
                        trControl  = train.control,
                        metric     = "Accuracy",
                        data       = arcene_pca_75_treino)
# Summarize the results
print(pred.pca.75.rf)
print(pred.pca.75.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.pca.75.rf$results$mtry, pred.pca.75.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0.3,0.9))
lines(pred.pca.75.rf$results$mtry, pred.pca.75.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.75.rf <- predict(pred.pca.75.rf,newdata = arcene_pca_75_teste)
cm.pca.75.rf <- confusionMatrix(arcene_pca_75_teste$labels,fit.pca.75.rf)

# Train the model (full dataset)
pred.pca.75.rftrees <- train(labels~.,
                        method     = "rf",
                        trControl  = train.control,
                        metric     = "Accuracy",
                        data       = arcene_pca_75)
# Plot Error (number of trees)
print(pred.pca.75.rftrees$finalModel)
plot(pred.pca.75.rftrees$finalModel)
pred.pca.75.rftrees$finalModel.legend <- if (is.null(pred.pca.75.rftrees$finalModel$test$err.rate)) {colnames(pred.pca.75.rftrees$finalModel$err.rate)} else {colnames(pred.pca.75.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.pca.75.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)

####################### PCA 85% ####

# Decision tree (Complexity Parameter)
# Train the model
pred.pca.85.cp <- train(labels~.,
                     method     = "rpart",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_85_treino)
# Summarize the results
print(pred.pca.85.cp)

# Plot Accuracy&Kappa
plot(pred.pca.85.cp$results$cp, pred.pca.85.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.8))
lines(pred.pca.85.cp$results$cp, pred.pca.85.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.85.cp <- predict(pred.pca.85.cp,newdata = arcene_pca_85_teste)
cm.pca.85.cp <- confusionMatrix(arcene_pca_85_teste$labels,fit.pca.85.cp)

# Decision tree (Max Depth)
# Train the model
pred.pca.85.depth <- train(labels~.,
                     method     = "rpart2",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_85_treino)
# Summarize the results
print(pred.pca.85.depth)

# Plot Accuracy&Kappa
plot(pred.pca.85.depth$results$maxdepth, pred.pca.85.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0.2,0.9))
lines(pred.pca.85.depth$results$maxdepth, pred.pca.85.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.85.depth <- predict(pred.pca.85.depth,newdata = arcene_pca_85_teste)
cm.pca.85.depth <- confusionMatrix(arcene_pca_85_teste$labels,fit.pca.85.depth)

# Random Forests
# Train the model
pred.pca.85.rf <- train(labels~.,
                           method     = "rf",
                           trControl  = train.control,
                           metric     = "Accuracy",
                           data       = arcene_pca_85_treino)
# Summarize the results
print(pred.pca.85.rf)
print(pred.pca.85.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.pca.85.rf$results$mtry, pred.pca.85.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0.3,0.8))
lines(pred.pca.85.rf$results$mtry, pred.pca.85.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.85.rf <- predict(pred.pca.85.rf,newdata = arcene_pca_85_teste)
cm.pca.85.rf <- confusionMatrix(arcene_pca_85_teste$labels,fit.pca.85.rf)

# Train the model (full dataset)
pred.pca.85.rftrees <- train(labels~.,
                             method     = "rf",
                             trControl  = train.control,
                             metric     = "Accuracy",
                             data       = arcene_pca_85)
# Plot Error (number of trees)
print(pred.pca.85.rftrees$finalModel)
plot(pred.pca.85.rftrees$finalModel)
pred.pca.85.rftrees$finalModel.legend <- if (is.null(pred.pca.85.rftrees$finalModel$test$err.rate)) {colnames(pred.pca.85.rftrees$finalModel$err.rate)} else {colnames(pred.pca.85.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.pca.85.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)


####################### PCA 95% ####

# Decision tree (Complexity Parameter)
# Train the model
pred.pca.95.cp <- train(labels~.,
                     method     = "rpart",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_95_treino)
# Summarize the results
print(pred.pca.95.cp)
# Plot Accuracy&Kappa
plot(pred.pca.95.cp$results$cp, pred.pca.95.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.7))
lines(pred.pca.95.cp$results$cp, pred.pca.95.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.95.cp <- predict(pred.pca.95.cp,newdata = arcene_pca_95_teste)
cm.pca.95.cp <- confusionMatrix(arcene_pca_95_teste$labels,fit.pca.95.cp)

# Decision tree (Max Depth)
# Train the model
pred.pca.95.depth <- train(labels~.,
                     method     = "rpart2",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_95_treino)
# Summarize the results
print(pred.pca.95.depth)

# Plot Accuracy&Kappa
plot(pred.pca.95.depth$results$maxdepth, pred.pca.95.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0.2,0.7))
lines(pred.pca.95.depth$results$maxdepth, pred.pca.95.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.95.depth <- predict(pred.pca.95.depth,newdata = arcene_pca_95_teste)
cm.pca.95.depth <- confusionMatrix(arcene_pca_95_teste$labels,fit.pca.95.depth)

# Random Forests
# Train the model
pred.pca.95.rf <- train(labels~.,
                        method     = "rf",
                        trControl  = train.control,
                        metric     = "Accuracy",
                        data       = arcene_pca_95_treino)
# Summarize the results
print(pred.pca.95.rf)
print(pred.pca.95.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.pca.95.rf$results$mtry, pred.pca.95.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0.1,0.8))
lines(pred.pca.95.rf$results$mtry, pred.pca.95.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.pca.95.rf <- predict(pred.pca.95.rf,newdata = arcene_pca_95_teste)
cm.pca.95.rf <- confusionMatrix(arcene_pca_95_teste$labels,fit.pca.95.rf)

# Train the model (full dataset)
pred.pca.95.rftrees <- train(labels~.,
                             method     = "rf",
                             trControl  = train.control,
                             metric     = "Accuracy",
                             data       = arcene_pca_95)
# Plot Error (number of trees)
print(pred.pca.95.rftrees$finalModel)
plot(pred.pca.95.rftrees$finalModel)
pred.pca.95.rftrees$finalModel.legend <- if (is.null(pred.pca.95.rftrees$finalModel$test$err.rate)) {colnames(pred.pca.95.rftrees$finalModel$err.rate)} else {colnames(pred.pca.95.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.pca.95.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)


####################### Correlation 75% ####

# Decision tree (Complexity Parameter)
#Train the model
pred.corr.75.cp <- train(labels~.,
                     method     = "rpart",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_corr_75_treino)
# Summarize the results
print(pred.corr.75.cp)
# Plot Accuracy&Kappa
plot(pred.corr.75.cp$results$cp, pred.corr.75.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.7))
lines(pred.corr.75.cp$results$cp, pred.corr.75.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.75.cp <- predict(pred.corr.75.cp,newdata = arcene_corr_75_teste)
cm.corr.75.cp <- confusionMatrix(arcene_corr_75_teste$labels,fit.corr.75.cp)

# Decision tree (Max Depth)
# Train the model
pred.corr.75.depth <- train(labels~.,
                      method     = "rpart2",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_75_treino)
# Summarize the results
print(pred.corr.75.depth)

# Plot Accuracy&Kappa
plot(pred.corr.75.depth$results$maxdepth, pred.corr.75.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0,0.8))
lines(pred.corr.75.depth$results$maxdepth, pred.corr.75.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.75.depth <- predict(pred.corr.75.depth,newdata = arcene_corr_75_teste)
cm.corr.75.depth <- confusionMatrix(arcene_corr_75_teste$labels,fit.corr.75.depth)

# Random Forests
# Train the model
pred.corr.75.rf <- train(labels~.,
                        method     = "rf",
                        trControl  = train.control,
                        metric     = "Accuracy",
                        data       = arcene_corr_75_treino)
# Summarize the results
print(pred.corr.75.rf)
print(pred.corr.75.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.corr.75.rf$results$mtry, pred.corr.75.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0,0.8))
lines(pred.corr.75.rf$results$mtry, pred.corr.75.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.75.rf <- predict(pred.corr.75.rf,newdata = arcene_corr_75_teste)
cm.corr.75.rf <- confusionMatrix(arcene_corr_75_teste$labels,fit.corr.75.rf)

# Train the model (full dataset)
pred.corr.75.rftrees <- train(labels~.,
                             method     = "rf",
                             trControl  = train.control,
                             metric     = "Accuracy",
                             data       = arcene_corr_75)
# Plot Error (number of trees)
print(pred.corr.75.rftrees$finalModel)
plot(pred.corr.75.rftrees$finalModel)
pred.corr.75.rftrees$finalModel.legend <- if (is.null(pred.corr.75.rftrees$finalModel$test$err.rate)) {colnames(pred.corr.75.rftrees$finalModel$err.rate)} else {colnames(pred.corr.75.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.corr.75.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)


####################### Correlation 85% ####

# Decision Tree (Complexity Parameter)
# Train the model
pred.corr.85.cp <- train(labels~.,
                      method     = "rpart",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_85_treino)
# Summarize the results
print(pred.corr.85.cp)

# Plot Accuracy&Kappa
plot(pred.corr.85.cp$results$cp, pred.corr.85.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.7))
lines(pred.corr.85.cp$results$cp, pred.corr.85.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.85.cp <- predict(pred.corr.85.cp,newdata = arcene_corr_85_teste)
cm.corr.85.cp <- confusionMatrix(arcene_corr_85_teste$labels,fit.corr.85.cp)

# Decision Tree (Max Depth)
# Train the model
pred.corr.85.depth <- train(labels~.,
                      method     = "rpart2",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_85_treino)
# Summarize the results
print(pred.corr.85.depth)

# Plot Accuracy&Kappa
plot(pred.corr.85.depth$results$maxdepth, pred.corr.85.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0,1))
lines(pred.corr.85.depth$results$maxdepth, pred.corr.85.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.85.depth <- predict(pred.corr.85.depth,newdata = arcene_corr_85_teste)
cm.corr.85.depth <- confusionMatrix(arcene_corr_85_teste$labels,fit.corr.85.depth)

# Random Forests
# Train the model
pred.corr.85.rf <- train(labels~.,
                         method     = "rf",
                         trControl  = train.control,
                         metric     = "Accuracy",
                         data       = arcene_corr_85_treino)
# Summarize the results
print(pred.corr.85.rf)
print(pred.corr.85.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.corr.85.rf$results$mtry, pred.corr.85.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0,0.8))
lines(pred.corr.85.rf$results$mtry, pred.corr.85.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.85.rf <- predict(pred.corr.85.rf,newdata = arcene_corr_85_teste)
cm.corr.85.rf <- confusionMatrix(arcene_corr_85_teste$labels,fit.corr.85.rf)

# Train the model (full dataset)
pred.corr.85.rftrees <- train(labels~.,
                              method     = "rf",
                              trControl  = train.control,
                              metric     = "Accuracy",
                              data       = arcene_corr_85)
# Plot Error (number of trees)
print(pred.corr.85.rftrees$finalModel)
plot(pred.corr.85.rftrees$finalModel)
pred.corr.85.rftrees$finalModel.legend <- if (is.null(pred.corr.85.rftrees$finalModel$test$err.rate)) {colnames(pred.corr.85.rftrees$finalModel$err.rate)} else {colnames(pred.corr.85.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.corr.85.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)

####################### Correlation 95% ####

# Decision Tree (Complexity Parameter)
# Train the model
pred.corr.95.cp <- train(labels~.,
                      method     = "rpart",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_95_treino)
# Summarize the results
print(pred.corr.95.cp)

# Plot Accuracy&Kappa
plot(pred.corr.95.cp$results$cp, pred.corr.95.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0,0.7))
lines(pred.corr.95.cp$results$cp, pred.corr.95.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.95.cp <- predict(pred.corr.95.cp,newdata = arcene_corr_95_teste)
cm.corr.95.cp <- confusionMatrix(arcene_corr_95_teste$labels,fit.corr.95.cp)

# Decision Tree (Max Depth)
# Train the model
pred.corr.95.depth <- train(labels~.,
                      method     = "rpart2",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_95_treino)
# Summarize the results
print(pred.corr.95.depth)

# Plot Accuracy&Kappa
plot(pred.corr.95.depth$results$maxdepth, pred.corr.95.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0,0.7))
lines(pred.corr.95.depth$results$maxdepth, pred.corr.95.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.95.depth <- predict(pred.corr.95.depth,newdata = arcene_corr_95_teste)
cm.corr.95.depth <- confusionMatrix(arcene_corr_95_teste$labels,fit.corr.95.depth)

# Random Forests
# Train the model
pred.corr.95.rf <- train(labels~.,
                         method     = "rf",
                         trControl  = train.control,
                         metric     = "Accuracy",
                         data       = arcene_corr_95_treino)
# Summarize the results
print(pred.corr.95.rf)
print(pred.corr.95.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.corr.95.rf$results$mtry, pred.corr.95.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0.3,0.9))
lines(pred.corr.95.rf$results$mtry, pred.corr.95.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.95.rf <- predict(pred.corr.95.rf,newdata = arcene_corr_95_teste)
cm.corr.95.rf <- confusionMatrix(arcene_corr_95_teste$labels,fit.corr.95.rf)

# Train the model (full dataset)
pred.corr.95.rftrees <- train(labels~.,
                              method     = "rf",
                              trControl  = train.control,
                              metric     = "Accuracy",
                              data       = arcene_corr_95)
# Plot Error (number of trees)
print(pred.corr.95.rftrees$finalModel)
plot(pred.corr.95.rftrees$finalModel)
pred.corr.95.rftrees$finalModel.legend <- if (is.null(pred.corr.95.rftrees$finalModel$test$err.rate)) {colnames(pred.corr.95.rftrees$finalModel$err.rate)} else {colnames(pred.corr.95.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.corr.95.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)


####################### Correlation 99% ####

# Decision Tree (Complexity Parameter)
# Train the model
pred.corr.99.cp <- train(labels~.,
                      method     = "rpart",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_99_treino)
# Summarize the results
print(pred.corr.99.cp)

# Plot Accuracy&Kappa
plot(pred.corr.99.cp$results$cp, pred.corr.99.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Score", ylim = c(0.1,0.8))
lines(pred.corr.99.cp$results$cp, pred.corr.99.cp$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("right", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.99.cp <- predict(pred.corr.99.cp,newdata = arcene_corr_99_teste)
cm.corr.99.cp <- confusionMatrix(arcene_corr_99_teste$labels,fit.corr.99.cp)

# Decision Tree (Max Depth)
# Train the model
pred.corr.99.depth <- train(labels~.,
                      method     = "rpart2",
                      trControl  = train.control,
                      metric     = "Accuracy",
                      data       = arcene_corr_99_treino)
# Summarize the results
print(pred.corr.99.depth)
# Plot Accuracy&Kappa
plot(pred.corr.99.depth$results$maxdepth, pred.corr.99.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Score", ylim = c(0.15,0.8))
lines(pred.corr.99.depth$results$maxdepth, pred.corr.99.depth$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.99.depth <- predict(pred.corr.99.depth,newdata = arcene_corr_99_teste)
cm.corr.99.depth <- confusionMatrix(arcene_corr_99_teste$labels,fit.corr.99.depth)

# Random Forests
# Train the model
pred.corr.99.rf <- train(labels~.,
                         method     = "rf",
                         trControl  = train.control,
                         metric     = "Accuracy",
                         data       = arcene_corr_99_treino)
# Summarize the results
print(pred.corr.99.rf)
print(pred.corr.99.rf$finalModel)

# Plot Accuracy&Kappa
plot(pred.corr.99.rf$results$mtry, pred.corr.99.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Predictors", ylab = "Score", ylim = c(0.3,0.9))
lines(pred.corr.99.rf$results$mtry, pred.corr.99.rf$results$Kappa, type = "b", pch = 15, col = "blue", lty = 2)
legend("bottomright", legend = c("Accuracy", "Kappa"), col = c("red", "blue"), lty = 1:2, cex = 0.8)

# Prediction
fit.corr.99.rf <- predict(pred.corr.99.rf,newdata = arcene_corr_99_teste)
cm.corr.99.rf <- confusionMatrix(arcene_corr_99_teste$labels,fit.corr.99.rf)

# Train the model (full dataset)
pred.corr.99.rftrees <- train(labels~.,
                              method     = "rf",
                              trControl  = train.control,
                              metric     = "Accuracy",
                              data       = arcene_corr_99)
# Plot Error (number of trees)
print(pred.corr.99.rftrees$finalModel)
plot(pred.corr.99.rftrees$finalModel)
pred.corr.99.rftrees$finalModel.legend <- if (is.null(pred.corr.99.rftrees$finalModel$test$err.rate)) {colnames(pred.corr.99.rftrees$finalModel$err.rate)} else {colnames(pred.corr.99.rftrees$finalModel$test$err.rate)}
legend("top", cex =0.7, legend=pred.corr.99.rftrees$finalModel.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)


####################### PLOTS ####
#Accuracy vs. Tree Depth - CORRELATION
plot(pred.corr.99.depth$results$maxdepth, pred.corr.99.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Accuracy Score", ylim = c(0.15,0.8), xlim = c(1,5), main = "")
lines(pred.corr.95.depth$results$maxdepth, pred.corr.95.depth$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.corr.85.depth$results$maxdepth, pred.corr.85.depth$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
lines(pred.corr.75.depth$results$maxdepth, pred.corr.75.depth$results$Accuracy, type = "b", pch = 15, col = "purple", lty = 4)
legend("bottomright", legend = c("pred.corr.99", "pred.corr.95", "pred.corr.85", "pred.corr.75"), col = c("red", "blue", "green", "purple"), lty = 1:4, cex = 0.8)
fancyRpartPlot(pred.corr.99.depth$finalModel)

#Accuracy vs. Tree Depth - PCA
plot(pred.pca.95.depth$results$maxdepth, pred.pca.95.depth$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Maximum Tree Depth", ylab = "Accuracy Score", ylim = c(0.5,0.8), xlim = c(1,3))
lines(pred.pca.85.depth$results$maxdepth, pred.pca.85.depth$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.pca.75.depth$results$maxdepth, pred.pca.75.depth$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
legend("bottomright", legend = c("pred.pca.95", "pred.pca.85", "pred.pca.75"), col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)
fancyRpartPlot(pred.pca.85.depth$finalModel)

#Accuracy vs. Complexity Parameter - CORRELATION
plot(pred.corr.99.cp$results$cp, pred.corr.99.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Accuracy Score", ylim = c(0.45,0.75), xlim = c(0.05,0.45))
lines(pred.corr.95.cp$results$cp, pred.corr.95.cp$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.corr.85.cp$results$cp, pred.corr.85.cp$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
lines(pred.corr.75.cp$results$cp, pred.corr.75.cp$results$Accuracy, type = "b", pch = 15, col = "purple", lty = 4)
legend("bottomright", legend = c("pred.corr.99", "pred.corr.95", "pred.corr.85", "pred.corr.75"), col = c("red", "blue", "green", "purple"), lty = 1:4, cex = 0.8)
fancyRpartPlot(pred.corr.99.cp$finalModel)

#Accuracy vs. Complexity Parameter - PCA
plot(pred.pca.95.cp$results$cp, pred.pca.95.cp$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Complexity Parameter", ylab = "Accuracy Score", ylim = c(0.5,0.75), xlim = c(0.05,0.4))
lines(pred.pca.85.cp$results$cp, pred.pca.85.cp$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.pca.75.cp$results$cp, pred.pca.75.cp$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
legend("topright", legend = c("pred.pca.95", "pred.pca.85", "pred.pca.75"), col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)
fancyRpartPlot(pred.pca.75.cp$finalModel)

#Accuracy vs. Randomly Selected Variables - CORRELATION
plot(pred.corr.99.rf$results$mtry, pred.corr.99.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", ylab = "Accuracy Score", xlab = "Randomly Selected Variables", ylim = c(0.45,1), xlim = c(0,4000))
lines(pred.corr.95.rf$results$mtry, pred.corr.95.rf$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.corr.85.rf$results$mtry, pred.corr.85.rf$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
lines(pred.corr.75.rf$results$mtry, pred.corr.75.rf$results$Accuracy, type = "b", pch = 15, col = "purple", lty = 4)
legend("bottomright", legend = c("pred.corr.99", "pred.corr.95", "pred.corr.85", "pred.corr.75"), col = c("red", "blue", "green", "purple"), lty = 1:4, cex = 0.8)

#Accuracy vs. Randomly Selected Variables - PCA
plot(pred.pca.95.rf$results$mtry, pred.pca.95.rf$results$Accuracy, type="b", frame = TRUE, pch = 19, col = "red", xlab = "Randomly Selected Variables", ylab = "Accuracy Score", ylim = c(0.5,1), xlim = c(1,200))
lines(pred.pca.85.rf$results$mtry, pred.pca.85.rf$results$Accuracy, type = "b", pch = 18, col = "blue", lty = 2)
lines(pred.pca.75.rf$results$mtry, pred.pca.75.rf$results$Accuracy, type = "b", pch = 17, col = "green", lty = 3)
legend("topright", legend = c("pred.pca.95", "pred.pca.85", "pred.pca.75"), col = c("red", "blue", "green"), lty = 1:3, cex = 0.8)

##Bar plot of all the results summarized
#Decision Trees - CP
resultscp=melt(data.frame(Correlation99=c(0.76, 0.733, 0.229, 0.579, 0.647),
                          Correlation95=c(0.76, 0.64, 0.12, 0.842, 0.727),
                          Correlation85=c(0.74, 0.875, 0.286, 0.368, 0.518),
                          Correlation75=c(0.66, 0.528, 0, 1, 0.691),
                          PCA95=c(0.68, 0.588, 0.273, 0.526, 0.555),
                          PCA85=c(0.68, 0.588, 0.273, 0.526, 0.555),
                          PCA75=c(0.68, 0.588, 0.273, 0.526, 0.555),
                          scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(resultscp)[2]<-"Process"
ggplot(resultscp,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")+labs(title = "Metric Scores (Decision Trees - Complexity Parameter)")

#Decision Trees - Maximum Tree Depth
resultsdepth=melt(data.frame(Correlation99=c(0.8, 0.714, 0.138, 0.789, 0.750),
                          Correlation95=c(0.72, 0.593, 0.13, 0.842, 0.696),
                          Correlation85=c(0.66, 0.55, 0.267, 0.579, 0.564),
                          Correlation75=c(0.66, 0.528, 0, 1, 0.691),
                          PCA95=c(0.64, 0.524, 0.276, 0.579, 0.550),
                          PCA85=c(0.62, 0.5, 0.269, 0.632, 0.558),
                          PCA75=c(0.64, 0.524, 0.276, 0.579, 0.550),
                          scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(resultsdepth)[2]<-"Process"
ggplot(resultsdepth,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")+labs(title = "Metric Scores (Decision Trees - Max. Tree Depth)")

#Random Forests
resultsrf=melt(data.frame(Correlation99=c(0.78, 0.7, 0.167, 0.737, 0.718),
                          Correlation95=c(0.78, 0.7, 0.167, 0.737, 0.718),
                          Correlation85=c(0.82, 0.778, 0.156, 0.737, 0.757),
                          Correlation75=c(0.8, 0.8, 0.2, 0.632, 0.706),
                          PCA95=c(0.76, 0.769, 0.243, 0.526, 0.625),
                          PCA85=c(0.68, 0.615, 0.297, 0.421, 0.500),
                          PCA75=c(0.82, 0.812 , 0.176, 0.684, 0.743),
                          scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(resultsrf)[2]<-"Process"
ggplot(resultsrf,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")+labs(title = "Metric Scores (Random Forests)")+ylim(0,1)

####################### Confusion Matrices #################

metricas(cm.pca.75.cp$table)
metricas(cm.pca.75.depth$table)
metricas(cm.pca.75.rf$table)
metricas(cm.pca.85.cp$table)
metricas(cm.pca.85.depth$table)
metricas(cm.pca.85.rf$table)
metricas(cm.pca.95.cp$table)
metricas(cm.pca.95.depth$table)
metricas(cm.pca.95.rf$table)
metricas(cm.corr.75.cp$table)
metricas(cm.corr.75.depth$table)
metricas(cm.corr.75.rf$table)
metricas(cm.corr.85.cp$table)
metricas(cm.corr.85.depth$table)
metricas(cm.corr.85.rf$table)
metricas(cm.corr.95.cp$table)
metricas(cm.corr.95.depth$table)
metricas(cm.corr.95.rf$table)
metricas(cm.corr.99.cp$table)
metricas(cm.corr.99.depth$table)
metricas(cm.corr.99.rf$table)

```



Naive Bayes method:
```{r}
grid1<-expand.grid(.fL=c(0),.usekernel=c(TRUE),.adjust=c(1:4))
grid2<-expand.grid(.fL=c(0),.usekernel=c(TRUE,FALSE),.adjust=c(1:4))

####################### Correlation 75% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.corr75 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid1,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_corr_75_treino))

suppressWarnings(fit_pred.nb.corr75 <- predict(pred.nb.corr75, newdata = arcene_corr_75_teste))
resultado_nb_corr75<-confusionMatrix(arcene_corr_75_teste$labels, fit_pred.nb.corr75)

metricas(resultado_nb_corr75$table)

####################### Correlation 85% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.corr85 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid1,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_corr_85_treino))

suppressWarnings(fit_pred.nb.corr85 <- predict(pred.nb.corr85, newdata = arcene_corr_85_teste))
resultado_nb_corr85<-confusionMatrix(arcene_corr_85_teste$labels, fit_pred.nb.corr85)

metricas(resultado_nb_corr85$table)

####################### Correlation 95% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.corr95 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid1,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_corr_95_treino))

suppressWarnings(fit_pred.nb.corr95 <- predict(pred.nb.corr95, newdata = arcene_corr_95_teste))
resultado_nb_corr95<-confusionMatrix(arcene_corr_95_teste$labels, fit_pred.nb.corr95)

metricas(resultado_nb_corr95$table)

####################### Correlation 99% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.corr99 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid1,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_corr_99_treino))

suppressWarnings(fit_pred.nb.corr99 <- predict(pred.nb.corr99, newdata = arcene_corr_99_teste))
resultado_nb_corr99<-confusionMatrix(arcene_corr_99_teste$labels, fit_pred.nb.corr99)

metricas(resultado_nb_corr99$table)

####################### PCA 75% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.pca75 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid2,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_pca_75_treino))

suppressWarnings(fit_pred.nb.pca75 <- predict(pred.nb.pca75, newdata = arcene_pca_75_teste))
resultado_nb_pca75<-confusionMatrix(arcene_pca_75_teste$labels, fit_pred.nb.pca75)

metricas(resultado_nb_pca75$table)

####################### PCA 85% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.pca85 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid2,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_pca_85_treino))

suppressWarnings(fit_pred.nb.pca85 <- predict(pred.nb.pca85, newdata = arcene_pca_85_teste))
resultado_nb_pca85<-confusionMatrix(arcene_pca_85_teste$labels, fit_pred.nb.pca85)

metricas(resultado_nb_pca85$table)

####################### PCA 95% ####
# Train the model
set.seed(2020)
suppressWarnings(pred.nb.pca95 <- train(labels~.,
                     method     = "nb",
                     tuneGrid   = grid2,
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data=arcene_pca_95_treino))

suppressWarnings(fit_pred.nb.pca95 <- predict(pred.nb.pca95, newdata = arcene_pca_95_teste))
resultado_nb_pca95<-confusionMatrix(arcene_pca_95_teste$labels,fit_pred.nb.pca95)

metricas(resultado_nb_pca95$table)


#Bar plot of all the metric scores
results_nb=melt(data.frame(Correlation99=c(0.7,0.571,0.136,0.842,0.681),
                    Correlation95=c(0.68,0.556,0.174,0.789,0.652),
                    Correlation85=c(0.46,0.357,0.409,0.526,0.425),
                    Correlation75=c(0.46,0.333,0.423,0.421,0.372),
                    PCA95=c(0.68,0.56,0.2,0.737,0.636),
                    PCA85=c(0.7,0.591,0.214,0.684,0.634),
                    PCA75=c(0.76,0.652,0.148,0.789,0.714),
                    scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(results_nb)[2]<-"Process"
ggplot(results_nb,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")

#Plot with accuracy depending on the tuning parameters
zindices<-c(0,1,2,3,4)
zcorr75<-c(NA,0.4881943,0.4870894,0.5217723,0.5075343)
zcorr85<-c(NA,0.5084242,0.5135261,0.5484538,0.533558)
zcorr95<-c(NA,0.5742158,0.6195625,0.6135855,0.5595625)
zcorr99<-c(NA,0.6520356,0.6582425,0.6382425,0.5855543)
zpca75<-c(NA,0.6787023,0.6724805,0.6587023,0.6128958)
zpca85<-c(NA,0.7067186,0.6658139,0.6524657,0.5393326)
zpca95<-c(NA,0.6393623,0.6729255,0.6460141,0.5722358)
zpca75false=c(0.6855840,NA,NA,NA,NA)
zpca85false=c(0.6791472,NA,NA,NA,NA)
zpca95false=c(0.6457990,NA,NA,NA,NA)
plot(zindices,zcorr99, type="b", col="purple", lwd=2, pch=18, xlab="Adjust Parameter", ylab="Accuracy",ylim=range(0.48,1))
lines(zindices, zcorr95, type="b", col="red", lwd=2, pch=15)
lines(zindices, zcorr85, type="b", col="blue", lwd=2, pch=15)
lines(zindices, zcorr75, type="b", col="green", lwd=2, pch=15)
lines(zindices, zpca95, type="b", col="yellow", lwd=2, pch=19)
lines(zindices, zpca85, type="b", col="cyan", lwd=2, pch=19)
lines(zindices, zpca75, type="b", col="orange", lwd=2, pch=19)
lines(zindices,zpca95false,type="b",col="yellow",lwd=2,pch=8)
lines(zindices,zpca85false,type="b",col="cyan",lwd=2,pch=8)
lines(zindices,zpca75false,type="b",col="orange",lwd=2,pch=8)
legend(3.2,0.99,c("Corr99","Corr95","Corr85","Corr75"), lwd=c(2,2,2,2), col=c("purple","red","blue","green"), pch=c(18,15,15,15), y.intersp=1.5)
legend(2.25,0.99,c("PCA95","PCA85","PCA75"), lwd=c(2,2,2), col=c("yellow","cyan","orange"), pch=c(19,19,19), y.intersp=1.5)
legend(0.05,0.99,c("PCA95, usekernel=False","PCA85, usekernel=False","PCA75, usekernel=False"), lwd=c(2,2,2), col=c("yellow","cyan","orange"),pch=c(8,8,8), y.intersp=1.5)

```



Logistic regression method
```{r}

####################### Correlation 75% ####
corr75 <- read_csv("Datasets/arcene_corr_75.csv")
corr75_teste <- read_csv("Datasets/arcene_corr_75_treino.csv")
corr75_treino <- read_csv("Datasets/arcene_corr_75_teste.csv")
corr75_teste$labels[corr75_teste$labels==-1] <- 0
corr75_treino$labels[corr75_treino$labels==-1] <- 0
corr75_treino$X1 <- NULL
corr75_teste$X1 <- NULL
corr75$labels <- as.factor(corr75$labels)
corr75_treino$labels <- as.factor(corr75_treino$labels)
corr75_teste$labels <- as.factor(corr75_teste$labels)

train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_corr_75 <- train(labels~.,
                          method     = "glm",
                          family="binomial",
                          trControl  = train.control,
                          metric="Accuracy",
                          data       = corr75_treino)


fit_glm_corr_75 <- predict(pred_glm_corr_75, corr75_teste)
cnf_mtx_glm_corr_75 <- confusionMatrix(corr75_teste$labels, fit_glm_corr_75)
print(cnf_mtx_glm_corr_75)

metricas(cnf_mtx_glm_corr_75$table)

####################### Correlation 85% ####
corr85 <- read_csv("Datasets/arcene_corr_85.csv")
corr85_teste <- read_csv("Datasets/arcene_corr_85_treino.csv")
corr85_treino <- read_csv("Datasets/arcene_corr_85_teste.csv")
corr85_teste$labels[corr85_teste$labels==-1] <- 0
corr85_treino$labels[corr85_treino$labels==-1] <- 0
corr85_treino$X1 <- NULL
corr85_teste$X1 <- NULL
corr85$labels <- as.factor(corr85$labels)
corr85_treino$labels <- as.factor(corr85_treino$labels)
corr85_teste$labels <- as.factor(corr85_teste$labels)

train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_corr_85 <- train(labels~.,
                          method     = "glm",
                          family="binomial",
                          trControl  = train.control,
                          metric="Accuracy",
                          data       = corr85_treino)


fit_glm_corr_85 <- predict(pred_glm_corr_85, corr85_teste)
cnf_mtx_glm_corr_85 <- confusionMatrix(corr85_teste$labels, fit_glm_corr_85)
print(cnf_mtx_glm_corr_85)

metricas(cnf_mtx_glm_corr_85$table)

####################### Correlation 95% ####
corr95 <- read_csv("Datasets/arcene_corr_95.csv")
corr95_teste <- read_csv("Datasets/arcene_corr_95_treino.csv")
corr95_treino <- read_csv("Datasets/arcene_corr_95_teste.csv")
corr95_teste$labels[corr95_teste$labels==-1] <- 0
corr95_treino$labels[corr95_treino$labels==-1] <- 0
corr95_treino$X1 <- NULL
corr95_teste$X1 <- NULL
corr95$labels <- as.factor(corr95$labels)
corr95_treino$labels <- as.factor(corr95_treino$labels)
corr95_teste$labels <- as.factor(corr95_teste$labels)



train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_corr_95 <- train(labels~.,
                          method     = "glm",
                          family="binomial",
                          trControl  = train.control,
                          metric="Accuracy",
                          data       = corr95_treino)


fit_glm_corr_95 <- predict(pred_glm_corr_95, corr95_teste)
cnf_mtx_glm_corr_95 <- confusionMatrix(corr95_teste$labels, fit_glm_corr_95)
print(cnf_mtx_glm_corr_95)

metricas(cnf_mtx_glm_corr_95$table)

####################### Correlation 99% ####
corr99 <- read_csv("Datasets/arcene_corr_99.csv")
corr99_teste <- read_csv("Datasets/arcene_corr_99_treino.csv")
corr99_treino <- read_csv("Datasets/arcene_corr_99_teste.csv")
corr99_teste$labels[corr99_teste$labels==-1] <- 0
corr99_treino$labels[corr99_treino$labels==-1] <- 0
corr99_treino$X1 <- NULL
corr99_teste$X1 <- NULL
corr99$labels <- as.factor(corr99$labels)
corr99_treino$labels <- as.factor(corr99_treino$labels)
corr99_teste$labels <- as.factor(corr99_teste$labels)



train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_corr_99 <- train(labels~.,
                          method     = "glm",
                          family="binomial",
                          trControl  = train.control,
                          metric="Accuracy",
                          data       = corr99_treino)


fit_glm_corr_99 <- predict(pred_glm_corr_99, corr99_teste)
cnf_mtx_glm_corr_99 <- confusionMatrix(corr99_teste$labels, fit_glm_corr_99)
print(cnf_mtx_glm_corr_99)

metricas(cnf_mtx_glm_corr_99$table)


####################### PCA 75% ####
pca75 <- read_csv("Datasets/arcene_pca_75.csv")
pca75_teste <- read_csv("Datasets/arcene_pca_75_treino.csv")
pca75_treino <- read_csv("Datasets/arcene_pca_75_teste.csv")
pca75_teste$labels[pca75_teste$labels==-1] <- 0
pca75_treino$labels[pca75_treino$labels==-1] <- 0
pca75_treino$X1 <- NULL
pca75_teste$X1 <- NULL
pca75$labels <- as.factor(pca75$labels)
pca75_treino$labels <- as.factor(pca75_treino$labels)
pca75_teste$labels <- as.factor(pca75_teste$labels)


train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_pca_75 <- train(labels~.,
                          method     = "glm",
                          family="binomial",
                          trControl  = train.control,
                          metric="Accuracy",
                          data       = pca75_treino)


fit_glm_pca_75 <- predict(pred_glm_pca_75, pca75_teste)
cnf_mtx_glm_pca_75 <- confusionMatrix(pca75_teste$labels, fit_glm_pca_75)
print(cnf_mtx_glm_pca_75)

metricas(cnf_mtx_glm_pca_75$table)

####################### PCA 85% ####
pca85 <- read_csv("Datasets/arcene_pca_85.csv")
pca85_teste <- read_csv("Datasets/arcene_pca_85_treino.csv")
pca85_treino <- read_csv("Datasets/arcene_pca_85_teste.csv")
pca85_teste$labels[pca85_teste$labels==-1] <- 0
pca85_treino$labels[pca85_treino$labels==-1] <- 0
pca85_treino$X1 <- NULL
pca85_teste$X1 <- NULL
pca85$labels <- as.factor(pca85$labels)
pca85_treino$labels <- as.factor(pca85_treino$labels)
pca85_teste$labels <- as.factor(pca85_teste$labels)

train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_pca_85 <- train(labels~.,
                         method     = "glm",
                         family="binomial",
                         trControl  = train.control,
                         metric="Accuracy",
                         data       = pca85_treino)


fit_glm_pca_85 <- predict(pred_glm_pca_85, pca85_teste)
cnf_mtx_glm_pca_85 <- confusionMatrix(pca85_teste$labels, fit_glm_pca_85)
print(cnf_mtx_glm_pca_85)

metricas(cnf_mtx_glm_pca_85$table)
####################### PCA 95% ####
pca95 <- read_csv("Datasets/arcene_pca_95.csv")
pca95_teste <- read_csv("Datasets/arcene_pca_95_treino.csv")
pca95_treino <- read_csv("Datasets/arcene_pca_95_teste.csv")
pca95_teste$labels[pca95_teste$labels==-1] <- 0
pca95_treino$labels[pca95_treino$labels==-1] <- 0
pca95_treino$X1 <- NULL
pca95_teste$X1 <- NULL
pca95$labels <- as.factor(pca95$labels)
pca95_treino$labels <- as.factor(pca95_treino$labels)
pca95_teste$labels <- as.factor(pca95_teste$labels)



train.control <- trainControl(method = "cv",number = 5)
set.seed(2020)
pred_glm_pca_95 <- train(labels~.,
                         method     = "glm",
                         family="binomial",
                         trControl  = train.control,
                         metric="Accuracy",
                         data       = pca95_treino)


fit_glm_pca_95 <- predict(pred_glm_pca_95, pca95_teste)
cnf_mtx_glm_pca_95 <- confusionMatrix(pca95_teste$labels, fit_glm_pca_95)
print(cnf_mtx_glm_pca_95)

metricas(cnf_mtx_glm_pca_95$table)



#Metric scores
resultsrf=melt(data.frame(Correlation99=c(0.48, 0.381, 0.407, 0.421, 0.348),
                          Correlation95=c(0.48, 0.458, 0.381, 0.579, 0.379),
                          Correlation85=c(0.54, 0.53, 0.3, 0.684, 0.433),
                          Correlation75=c(0.4, 0.318, 0.48, 0.368, 0.28),
                          PCA95=c(0.66, 0.605, 0.231, 0.684, 0.542),
                          PCA85=c(0.78, 0.718, 0.167, 0.737, 0.7),
                          PCA75=c(0.8, 0.737 , 0.161, 0.737, 0.737),
                          scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(resultsrf)[2]<-"Process"
ggplot(resultsrf,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")+labs(title = "Metric Scores (Logistic Regression)")+ylim(0,1)
```




Linear Discriminant Analysis method
```{r}
####################### PCA 75% ####

# Define training control
set.seed(3000)
# Train the model
pred.pca.75 <- train(labels~.,
                     method     = "lda",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_75_treino)
# Summarize the results
print(pred.pca.75)
fit.pca.75<-predict(pred.pca.75,newdata = arcene_pca_75_teste)
c75<-confusionMatrix(arcene_pca_75_teste$labels,fit.pca.75)

####################### PCA 85% ####

# Define training control
set.seed(3000)
# Train the model
pred.pca.85 <- train(labels~.,
                     method     = "lda",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_85_treino)
# Summarize the results
print(pred.pca.85)
fit.pca.85<-predict(pred.pca.85,newdata = arcene_pca_85_teste)
c85<-confusionMatrix(arcene_pca_85_teste$labels,fit.pca.85)

####################### PCA 95% ####

# Define training control
set.seed(3000)
# Train the model
pred.pca.95 <- train(labels~.,
                     method     = "lda",
                     trControl  = train.control,
                     metric     = "Accuracy",
                     data       = arcene_pca_95_treino)
# Summarize the results
print(pred.pca.95)
fit.pca.95<-predict(pred.pca.95,newdata = arcene_pca_95_teste)
c95<-confusionMatrix(arcene_pca_95_teste$labels,fit.pca.95)


metricas(c75$table)
metricas(c85$table)
metricas(c95$table)


#Metric scores
results=melt(data.frame(PCA75=c(0.8,0.737,0.161,0.737,0.737),
                        PCA85=c(0.86,0.75,0.038,0.947,0.837),
                        PCA95=c(0.64,0.524,0.276,0.579,0.55),
                        scores=c("Accuracy","TPR","FPR","Precision","F1 Score")))
colnames(results)[2]<-"Process"
ggplot(results,aes(scores, value,fill=Process))+geom_bar(position="dodge",stat="identity")

```

